{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from tqdm import tqdm # adds progress bar \n",
    "import urllib.parse # extract candidate ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code to get all 20_000 links in this\n",
    "\n",
    "Takes about 14 minutes\n",
    "\n",
    "Although, there appears to be other links that are not sequential. such as Councilor Rory O'Connor: https://www.irelandelection.com/candidate.php?candid=18829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:00<00:00, 26.47it/s]\n"
     ]
    }
   ],
   "source": [
    "number_of_links = 20\n",
    "failed = [] # list to store failed attempts\n",
    "my_timeout = aiohttp.ClientTimeout(\n",
    "    total=None, # default value is 5 minutes, set to `None` for unlimited timeout\n",
    "    sock_connect=150, # How long to wait before an open socket allowed to connect\n",
    "    sock_read=150 # How long to wait with no data being read before timing out\n",
    ")\n",
    "\n",
    "client_args = dict(\n",
    "    trust_env=True,\n",
    "    timeout=my_timeout\n",
    ")\n",
    "\n",
    "\n",
    "async def fetch(session, url, pbar):\n",
    "    \"\"\"Fetch a url, using specified ClientSession.\"\"\"\n",
    "    async with session.get(url) as response:\n",
    "        try:\n",
    "            resp = await response.read()\n",
    "            pbar.update(1)\n",
    "            return (url, resp)\n",
    "        except asyncio.TimeoutError:\n",
    "            failed.append(url)\n",
    "            print('timeout')\n",
    "            pbar.update(1)\n",
    "            return {\"results\": f\"timeout error on {url}\"}\n",
    "        if response.status != 200:\n",
    "            failed.append(url)\n",
    "            print('error')\n",
    "            pbar.update(1)\n",
    "            return {\"error\": f\"server returned {response.status}\"}\n",
    "\n",
    "async def get_responses(session, pbar):\n",
    "    tasks = []\n",
    "    for i in range(1, number_of_links):\n",
    "        url = f'https://www.irelandelection.com/candidate.php?candid={i}'\n",
    "        tasks.append(fetch(session, url, pbar))\n",
    "    responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return responses\n",
    "\n",
    "connector = aiohttp.TCPConnector(limit=60)\n",
    "async with aiohttp.ClientSession(connector=connector,**client_args) as s:\n",
    "    with tqdm(total=number_of_links) as pbar:\n",
    "        responses = await get_responses(s, pbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on these links:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "print('Failed on these links:\\n',failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for getting data from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_name(soup):\n",
    "    name = soup.find('title').text.split(' - ')[0].strip()\n",
    "    return name\n",
    "\n",
    "def get_election_type(election_string):\n",
    "    election_string = election_string.lower()\n",
    "    if 'local election' in election_string:\n",
    "        return 'LOCAL'\n",
    "    elif 'general election' in election_string:\n",
    "        return 'GENERAL'\n",
    "    elif 'european election' in election_string:\n",
    "        return 'EUROPEAN'\n",
    "    elif 'presidential election' in election_string:\n",
    "        return 'PRESIDENTIAL'\n",
    "    elif 'by-election' in election_string:\n",
    "        return 'BI-ELECTION'\n",
    "    \n",
    "def get_constituency_name(election_string):\n",
    "    constituency =  election_string.split(' - ')[1].strip()\n",
    "    return constituency\n",
    "\n",
    "def process_row(row):\n",
    "    d = {}\n",
    "    count = 0\n",
    "    column_names = ['election','first_pref_pct','first_pref_count','first_pref_quota_ratio','elected']\n",
    "    for td in row.find_all('td'):\n",
    "        txt = td.text\n",
    "        if txt:\n",
    "            d[column_names[count]] = txt.strip()\n",
    "            count+=1\n",
    "            d['elected'] = True if td.find('img') else False\n",
    "        elif td.find('img').get('title'):\n",
    "            d['party'] = td.find('img').get('title')\n",
    "    return d\n",
    "    \n",
    "def extract_table(soup):\n",
    "    list_of_rows = []\n",
    "    table_body = soup.find('tbody')\n",
    "    if not table_body:\n",
    "        raise Exception('No Table Found')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        d = process_row(row)\n",
    "        list_of_rows.append(d)\n",
    "    return list_of_rows\n",
    "\n",
    "def create_dataframe(name,list_of_rows,candid_id):\n",
    "    df = pd.DataFrame(list_of_rows)\n",
    "    df['elected'] = df.elected.fillna(False)\n",
    "    df['year'] = df.election.apply(lambda election_string: int(election_string[:4]))\n",
    "    df['candidate'] = name\n",
    "    df['constituency'] = df.election.apply(get_constituency_name)\n",
    "    df['election_type'] = df.election.apply(get_election_type)\n",
    "    df['candid_id'] = \n",
    "    return df\n",
    "\n",
    "def extract_data_from_page(res,candid_id):\n",
    "    soup = BeautifulSoup(res)\n",
    "    if len(list(soup.stripped_strings)) == 3:\n",
    "        raise Exception('Empty Page')\n",
    "    name = get_candidate_name(soup)\n",
    "    id_rep = soup.find('id').text.split(' - ')[0].strip()\n",
    "    rows = extract_table(soup)\n",
    "    df = create_dataframe(name,rows,candid_id)\n",
    "    return df\n",
    "\n",
    "def get_candid_id(url) \n",
    "    \n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    query_string = parsed_url.query\n",
    "    query_string_dict = urllib.parse.parse_qs(query_string)\n",
    "    candid_id = query_string_dict['candid'][0]\n",
    "    \n",
    "    return candid_id\n",
    "\n",
    "#extract_data_from_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.irelandelection.com/candidate.php?candid=1\n",
      "https://www.irelandelection.com/candidate.php?candid=2\n",
      "https://www.irelandelection.com/candidate.php?candid=3\n",
      "https://www.irelandelection.com/candidate.php?candid=4\n",
      "https://www.irelandelection.com/candidate.php?candid=5\n",
      "https://www.irelandelection.com/candidate.php?candid=6\n",
      "https://www.irelandelection.com/candidate.php?candid=7\n",
      "https://www.irelandelection.com/candidate.php?candid=8\n",
      "https://www.irelandelection.com/candidate.php?candid=9\n",
      "https://www.irelandelection.com/candidate.php?candid=10\n",
      "https://www.irelandelection.com/candidate.php?candid=11\n",
      "https://www.irelandelection.com/candidate.php?candid=12\n",
      "https://www.irelandelection.com/candidate.php?candid=13\n",
      "https://www.irelandelection.com/candidate.php?candid=14\n",
      "https://www.irelandelection.com/candidate.php?candid=15\n",
      "https://www.irelandelection.com/candidate.php?candid=16\n",
      "https://www.irelandelection.com/candidate.php?candid=17\n",
      "https://www.irelandelection.com/candidate.php?candid=18\n",
      "https://www.irelandelection.com/candidate.php?candid=19\n"
     ]
    }
   ],
   "source": [
    "list_of_dataframes = []\n",
    "fails = []\n",
    "for (url,resp) in responses:\n",
    "    #print(url)\n",
    "    try:\n",
    "        candid_id = get_candid_id(url) # getting the id from url \n",
    "        dataframe = extract_data_from_page(resp,candid_id)\n",
    "        list_of_dataframes.append(dataframe)\n",
    "    except Exception as e: \n",
    "        print('Failed:',url)\n",
    "        print(e,'\\n------------------------')\n",
    "        if str(e) == 'No Table Found':\n",
    "            fails.append((url,resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have to run throught the failed ones before concatinating the dataframes. \n",
    "\n",
    "Fails happen for 2 reasons:\n",
    "- The page is empty eg: https://www.irelandelection.com/candidate.php?candid=30\n",
    "- The page didnt return anything because I sent so many requests that their server couldnt respond.\n",
    "\n",
    "We send the requests back through again for the failed because of lack of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails2 = []\n",
    "tasks = []\n",
    "\n",
    "connector = aiohttp.TCPConnector(limit=60)\n",
    "async with aiohttp.ClientSession(connector=connector,**client_args) as s:\n",
    "    for (url,resp) in fails:\n",
    "        tasks.append(fetch(s,url)) \n",
    "    responses2 = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "\n",
    "for (url,resp) in responses2:\n",
    "    #print(url)\n",
    "    try:\n",
    "        dataframe = extract_data_from_page(resp)\n",
    "        list_of_dataframes.append(dataframe)\n",
    "    except Exception as e: \n",
    "        print('Failed:',url)\n",
    "        print(e,'\\n------------------------')\n",
    "        if str(e) == 'No Table Found':\n",
    "            fails2.append(\n",
    "                (url,resp)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(fails2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "election                  object\n",
       "elected                     bool\n",
       "party                     object\n",
       "first_pref_pct            object\n",
       "first_pref_count          object\n",
       "first_pref_quota_ratio    object\n",
       "year                       int64\n",
       "candidate                 object\n",
       "constituency              object\n",
       "election_type             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.concat(list_of_dataframes)\n",
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "election                   object\n",
       "elected                      bool\n",
       "party                      object\n",
       "first_pref_pct            float64\n",
       "first_pref_count            int32\n",
       "first_pref_quota_ratio    float64\n",
       "year                        int64\n",
       "candidate                  object\n",
       "constituency               object\n",
       "election_type              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['first_pref_pct'] = DF['first_pref_pct'].replace('Candidate for forthcoming election',None)\n",
    "DF['first_pref_pct'] = DF['first_pref_pct'].str.replace('%','').astype(float)/100\n",
    "DF['first_pref_count'] = DF.first_pref_count.fillna(0).astype(int)\n",
    "DF['first_pref_quota_ratio'] = DF.first_pref_quota_ratio.astype(float)\n",
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_parquet('ALL_CANDIDATES.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every elections we want\n",
    "- Number of Constituencies\n",
    "- How many consituency do we have vote data on?\n",
    "- What was the quota?\n",
    "- What was the votes/quota in first count?\n",
    "- What was the lowest votes/quota?\n",
    "- What was the highest votes/quota?\n",
    "- Who transfered to who (if you have transfer data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "21492c4fe8720d6af13e280c2b801faa6d368fda036b4f197ba5cbd3f78878df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
